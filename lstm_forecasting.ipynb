{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "\n",
        "# Load your stock data\n",
        "data = pd.read_csv('/content/stock_data.csv')\n",
        "data['date'] = pd.to_datetime(data['date'])\n",
        "data.set_index('date', inplace=True)\n",
        "\n",
        "# Step 1: Calculate stock-specific features\n",
        "stock_features = data.groupby('context_id').agg({\n",
        "    'volume': ['mean'],\n",
        "    'close': ['std', 'mean'],\n",
        "}).reset_index()\n",
        "\n",
        "# Flatten column names\n",
        "stock_features.columns = ['context_id', 'avg_volume', 'volatility', 'avg_price']\n",
        "\n",
        "# Step 2: Normalize numerical features\n",
        "scaler = StandardScaler()\n",
        "stock_features[['avg_volume', 'volatility', 'avg_price']] = scaler.fit_transform(\n",
        "    stock_features[['avg_volume', 'volatility', 'avg_price']]\n",
        ")\n",
        "\n",
        "# Step 3: Cluster stocks using K-means\n",
        "X_cluster = stock_features[['avg_volume', 'volatility', 'avg_price']]\n",
        "num_clusters = 5  # Adjust the number of clusters to speed up training\n",
        "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
        "stock_features['cluster'] = kmeans.fit_predict(X_cluster)\n",
        "\n",
        "# Merge cluster labels back into the main data\n",
        "data = data.reset_index().merge(stock_features[['context_id', 'cluster']], on='context_id', how='left')\n",
        "\n",
        "# Step 4: Prepare the time-series data for each cluster with additional seasonal features\n",
        "n_past = 252\n",
        "X_dict = {}\n",
        "y_dict = {}\n",
        "\n",
        "for cluster in range(num_clusters):\n",
        "    cluster_data = data[data['cluster'] == cluster].copy()  # Use `.copy()` to avoid the warning\n",
        "\n",
        "    # Add day of the week and day of the year as additional features using .loc\n",
        "    cluster_data.loc[:, 'day_of_week'] = cluster_data['date'].dt.dayofweek\n",
        "    cluster_data.loc[:, 'day_of_year'] = cluster_data['date'].dt.dayofyear\n",
        "\n",
        "    # Create a DataFrame of average daily close prices for all stocks in the cluster\n",
        "    avg_cluster_prices = cluster_data.groupby('date')['close'].mean().values.reshape(-1, 1)\n",
        "\n",
        "    # Scale the close prices for the LSTM\n",
        "    scaler = StandardScaler()\n",
        "    prices_scaled = scaler.fit_transform(avg_cluster_prices).flatten()\n",
        "\n",
        "    # Prepare time-series sequences for LSTM\n",
        "    X, y = [], []\n",
        "    for i in range(n_past, len(prices_scaled)):\n",
        "        past_prices = prices_scaled[i - n_past:i]\n",
        "        day_of_week = cluster_data['day_of_week'].values[i]\n",
        "        day_of_year = cluster_data['day_of_year'].values[i]\n",
        "\n",
        "        # Combine past prices with the seasonal features\n",
        "        X.append(np.concatenate([past_prices, [day_of_week, day_of_year]]))\n",
        "        y.append(prices_scaled[i])\n",
        "\n",
        "    X_dict[cluster] = np.array(X)\n",
        "    y_dict[cluster] = np.array(y)\n",
        "\n",
        "\n",
        "# Step 5: Train LSTM models without hyperparameter tuning\n",
        "\n",
        "# Directory to save the models\n",
        "save_dir = 'trained_lstm_models'\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "lstm_models = {}\n",
        "for cluster in range(num_clusters):\n",
        "    X_train = X_dict[cluster]\n",
        "    y_train = y_dict[cluster]\n",
        "\n",
        "    # Reshape input data for LSTM\n",
        "    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "\n",
        "    # Split into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, shuffle=False)\n",
        "\n",
        "    # Define the LSTM model\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(units=128, return_sequences=True, input_shape=(n_past + 2, 1)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(LSTM(units=64))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_absolute_error'])\n",
        "\n",
        "    # Add EarlyStopping callback\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(X_train, y_train, epochs=12, batch_size=128, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
        "\n",
        "    # Store the trained model for this cluster\n",
        "    lstm_models[cluster] = model\n",
        "\n",
        "    # Save the trained model for future use\n",
        "    model_path = os.path.join(save_dir, f'lstm_model_cluster_{cluster}.h5')\n",
        "    model.save(model_path)\n",
        "    print(f\"Model for cluster {cluster} saved to {model_path}\")\n",
        "\n",
        "    print(f\"Trained LSTM model for cluster {cluster}\")\n",
        "    model.summary()\n",
        "\n",
        "    # Make predictions on the test set\n",
        "    predictions_test = model.predict(X_test)\n",
        "\n",
        "    # Calculate performance metrics\n",
        "    mae_test = mean_absolute_error(y_test, predictions_test)\n",
        "    mse_test = mean_squared_error(y_test, predictions_test)\n",
        "    r2_test = r2_score(y_test, predictions_test)\n",
        "    mape_test = mean_absolute_percentage_error(y_test, predictions_test)\n",
        "\n",
        "    print(f'Testing Set Metrics for Cluster {cluster} - MAE: {mae_test}, MSE: {mse_test}, R2: {r2_test}, MAPE: {mape_test}')\n",
        "\n",
        "# At this point, each cluster's model has been trained and evaluated.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRZe1eQYOO0T",
        "outputId": "ae0e8c6c-f6f6-4331-db4a-948a7d7a892a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12\n",
            "38/38 [==============================] - 30s 705ms/step - loss: 0.0425 - mean_absolute_error: 0.1445 - val_loss: 0.1097 - val_mean_absolute_error: 0.2326\n",
            "Epoch 2/12\n",
            "38/38 [==============================] - 26s 687ms/step - loss: 0.0074 - mean_absolute_error: 0.0680 - val_loss: 0.2446 - val_mean_absolute_error: 0.3855\n",
            "Epoch 3/12\n",
            "38/38 [==============================] - 26s 694ms/step - loss: 0.0053 - mean_absolute_error: 0.0575 - val_loss: 0.2321 - val_mean_absolute_error: 0.3741\n",
            "Epoch 4/12\n",
            "38/38 [==============================] - 26s 683ms/step - loss: 0.0044 - mean_absolute_error: 0.0519 - val_loss: 0.2125 - val_mean_absolute_error: 0.3553\n",
            "Model for cluster 0 saved to trained_lstm_models/lstm_model_cluster_0.h5\n",
            "Trained LSTM model for cluster 0\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_2 (LSTM)               (None, 254, 128)          66560     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 254, 128)          0         \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 64)                49408     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116033 (453.25 KB)\n",
            "Trainable params: 116033 (453.25 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "38/38 [==============================] - 5s 104ms/step\n",
            "Testing Set Metrics for Cluster 0 - MAE: 0.23257471949578712, MSE: 0.10968451993091594, R2: 0.7511358516214363, MAPE: 0.125239178104965\n",
            "Epoch 1/12\n",
            "38/38 [==============================] - 30s 705ms/step - loss: 0.0402 - mean_absolute_error: 0.1389 - val_loss: 0.3175 - val_mean_absolute_error: 0.4920\n",
            "Epoch 2/12\n",
            "38/38 [==============================] - 26s 689ms/step - loss: 0.0053 - mean_absolute_error: 0.0570 - val_loss: 0.2574 - val_mean_absolute_error: 0.4335\n",
            "Epoch 3/12\n",
            "38/38 [==============================] - 26s 683ms/step - loss: 0.0043 - mean_absolute_error: 0.0506 - val_loss: 0.1951 - val_mean_absolute_error: 0.3683\n",
            "Epoch 4/12\n",
            "38/38 [==============================] - 26s 683ms/step - loss: 0.0036 - mean_absolute_error: 0.0468 - val_loss: 0.1611 - val_mean_absolute_error: 0.3318\n",
            "Epoch 5/12\n",
            "38/38 [==============================] - 26s 684ms/step - loss: 0.0032 - mean_absolute_error: 0.0444 - val_loss: 0.1665 - val_mean_absolute_error: 0.3404\n",
            "Epoch 6/12\n",
            "38/38 [==============================] - 26s 690ms/step - loss: 0.0032 - mean_absolute_error: 0.0433 - val_loss: 0.1380 - val_mean_absolute_error: 0.3121\n",
            "Epoch 7/12\n",
            "38/38 [==============================] - 26s 686ms/step - loss: 0.0029 - mean_absolute_error: 0.0411 - val_loss: 0.0911 - val_mean_absolute_error: 0.2395\n",
            "Epoch 8/12\n",
            "38/38 [==============================] - 26s 683ms/step - loss: 0.0027 - mean_absolute_error: 0.0402 - val_loss: 0.0780 - val_mean_absolute_error: 0.2210\n",
            "Epoch 9/12\n",
            "38/38 [==============================] - 26s 684ms/step - loss: 0.0026 - mean_absolute_error: 0.0394 - val_loss: 0.0768 - val_mean_absolute_error: 0.2226\n",
            "Epoch 10/12\n",
            "38/38 [==============================] - 27s 700ms/step - loss: 0.0024 - mean_absolute_error: 0.0378 - val_loss: 0.0691 - val_mean_absolute_error: 0.2123\n",
            "Epoch 11/12\n",
            "38/38 [==============================] - 26s 684ms/step - loss: 0.0025 - mean_absolute_error: 0.0385 - val_loss: 0.0337 - val_mean_absolute_error: 0.1366\n",
            "Epoch 12/12\n",
            "38/38 [==============================] - 26s 690ms/step - loss: 0.0022 - mean_absolute_error: 0.0365 - val_loss: 0.0290 - val_mean_absolute_error: 0.1264\n",
            "Model for cluster 1 saved to trained_lstm_models/lstm_model_cluster_1.h5\n",
            "Trained LSTM model for cluster 1\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_4 (LSTM)               (None, 254, 128)          66560     \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 254, 128)          0         \n",
            "                                                                 \n",
            " lstm_5 (LSTM)               (None, 64)                49408     \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116033 (453.25 KB)\n",
            "Trainable params: 116033 (453.25 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "38/38 [==============================] - 5s 102ms/step\n",
            "Testing Set Metrics for Cluster 1 - MAE: 0.12638275203477586, MSE: 0.02897712037178297, R2: 0.888370988457519, MAPE: 0.06702674027341333\n",
            "Epoch 1/12\n",
            "38/38 [==============================] - 30s 700ms/step - loss: 0.0339 - mean_absolute_error: 0.1354 - val_loss: 0.6624 - val_mean_absolute_error: 0.5615\n",
            "Epoch 2/12\n",
            "38/38 [==============================] - 26s 683ms/step - loss: 0.0046 - mean_absolute_error: 0.0539 - val_loss: 0.8472 - val_mean_absolute_error: 0.6787\n",
            "Epoch 3/12\n",
            "38/38 [==============================] - 26s 684ms/step - loss: 0.0028 - mean_absolute_error: 0.0425 - val_loss: 0.9481 - val_mean_absolute_error: 0.7290\n",
            "Epoch 4/12\n",
            "38/38 [==============================] - 26s 681ms/step - loss: 0.0023 - mean_absolute_error: 0.0383 - val_loss: 0.9691 - val_mean_absolute_error: 0.7447\n",
            "Model for cluster 2 saved to trained_lstm_models/lstm_model_cluster_2.h5\n",
            "Trained LSTM model for cluster 2\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_6 (LSTM)               (None, 254, 128)          66560     \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 254, 128)          0         \n",
            "                                                                 \n",
            " lstm_7 (LSTM)               (None, 64)                49408     \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116033 (453.25 KB)\n",
            "Trainable params: 116033 (453.25 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "38/38 [==============================] - 5s 105ms/step\n",
            "Testing Set Metrics for Cluster 2 - MAE: 0.5614537565328929, MSE: 0.6623605118640655, R2: 0.190415135882965, MAPE: 0.247432189744245\n",
            "Epoch 1/12\n",
            "38/38 [==============================] - 30s 711ms/step - loss: 0.0359 - mean_absolute_error: 0.1341 - val_loss: 0.1822 - val_mean_absolute_error: 0.2611\n",
            "Epoch 2/12\n",
            "38/38 [==============================] - 26s 690ms/step - loss: 0.0074 - mean_absolute_error: 0.0663 - val_loss: 0.3673 - val_mean_absolute_error: 0.4280\n",
            "Epoch 3/12\n",
            "38/38 [==============================] - 26s 694ms/step - loss: 0.0049 - mean_absolute_error: 0.0549 - val_loss: 0.2819 - val_mean_absolute_error: 0.3562\n",
            "Epoch 4/12\n",
            "38/38 [==============================] - 26s 698ms/step - loss: 0.0040 - mean_absolute_error: 0.0490 - val_loss: 0.2402 - val_mean_absolute_error: 0.3273\n",
            "Model for cluster 3 saved to trained_lstm_models/lstm_model_cluster_3.h5\n",
            "Trained LSTM model for cluster 3\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_8 (LSTM)               (None, 254, 128)          66560     \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 254, 128)          0         \n",
            "                                                                 \n",
            " lstm_9 (LSTM)               (None, 64)                49408     \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116033 (453.25 KB)\n",
            "Trainable params: 116033 (453.25 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "38/38 [==============================] - 4s 102ms/step\n",
            "Testing Set Metrics for Cluster 3 - MAE: 0.26111213615513457, MSE: 0.18219778588027907, R2: 0.6918125207825216, MAPE: 0.13884640306852544\n",
            "Epoch 1/12\n",
            "38/38 [==============================] - 31s 727ms/step - loss: 0.0473 - mean_absolute_error: 0.1413 - val_loss: 0.1355 - val_mean_absolute_error: 0.3124\n",
            "Epoch 2/12\n",
            "38/38 [==============================] - 26s 697ms/step - loss: 0.0066 - mean_absolute_error: 0.0634 - val_loss: 0.1157 - val_mean_absolute_error: 0.2906\n",
            "Epoch 3/12\n",
            "38/38 [==============================] - 26s 698ms/step - loss: 0.0052 - mean_absolute_error: 0.0565 - val_loss: 0.1136 - val_mean_absolute_error: 0.2902\n",
            "Epoch 4/12\n",
            "38/38 [==============================] - 26s 690ms/step - loss: 0.0044 - mean_absolute_error: 0.0517 - val_loss: 0.0879 - val_mean_absolute_error: 0.2514\n",
            "Epoch 5/12\n",
            "38/38 [==============================] - 26s 687ms/step - loss: 0.0040 - mean_absolute_error: 0.0494 - val_loss: 0.0577 - val_mean_absolute_error: 0.1972\n",
            "Epoch 6/12\n",
            "38/38 [==============================] - 26s 693ms/step - loss: 0.0037 - mean_absolute_error: 0.0466 - val_loss: 0.0651 - val_mean_absolute_error: 0.2142\n",
            "Epoch 7/12\n",
            "38/38 [==============================] - 26s 694ms/step - loss: 0.0036 - mean_absolute_error: 0.0456 - val_loss: 0.0589 - val_mean_absolute_error: 0.2036\n",
            "Epoch 8/12\n",
            "38/38 [==============================] - 26s 692ms/step - loss: 0.0033 - mean_absolute_error: 0.0441 - val_loss: 0.0571 - val_mean_absolute_error: 0.1981\n",
            "Epoch 9/12\n",
            "38/38 [==============================] - 26s 689ms/step - loss: 0.0033 - mean_absolute_error: 0.0446 - val_loss: 0.0521 - val_mean_absolute_error: 0.1921\n",
            "Epoch 10/12\n",
            "38/38 [==============================] - 26s 692ms/step - loss: 0.0034 - mean_absolute_error: 0.0450 - val_loss: 0.0458 - val_mean_absolute_error: 0.1760\n",
            "Epoch 11/12\n",
            "38/38 [==============================] - 26s 686ms/step - loss: 0.0032 - mean_absolute_error: 0.0436 - val_loss: 0.0424 - val_mean_absolute_error: 0.1713\n",
            "Epoch 12/12\n",
            "38/38 [==============================] - 26s 685ms/step - loss: 0.0030 - mean_absolute_error: 0.0421 - val_loss: 0.0280 - val_mean_absolute_error: 0.1360\n",
            "Model for cluster 4 saved to trained_lstm_models/lstm_model_cluster_4.h5\n",
            "Trained LSTM model for cluster 4\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_10 (LSTM)              (None, 254, 128)          66560     \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 254, 128)          0         \n",
            "                                                                 \n",
            " lstm_11 (LSTM)              (None, 64)                49408     \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116033 (453.25 KB)\n",
            "Trainable params: 116033 (453.25 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "38/38 [==============================] - 5s 103ms/step\n",
            "Testing Set Metrics for Cluster 4 - MAE: 0.13595019500814254, MSE: 0.02797635279429286, R2: 0.8789739484556198, MAPE: 0.08543988440226882\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "num_clusters = 5\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "\n",
        "save_dir = 'trained_lstm_models'\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# Load the saved models back for inference\n",
        "lstm_models = {}\n",
        "for cluster in range(num_clusters):\n",
        "    model_path = os.path.join(save_dir, f'lstm_model_cluster_{cluster}.h5')\n",
        "    model = load_model(model_path)\n",
        "    lstm_models[cluster] = model\n",
        "    print(f\"Model for cluster {cluster} loaded from {model_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqEgT4b8XJ5v",
        "outputId": "fc68f94a-0439-4f39-c8ed-96378eace807"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model for cluster 0 loaded from trained_lstm_models/lstm_model_cluster_0.h5\n",
            "Model for cluster 1 loaded from trained_lstm_models/lstm_model_cluster_1.h5\n",
            "Model for cluster 2 loaded from trained_lstm_models/lstm_model_cluster_2.h5\n",
            "Model for cluster 3 loaded from trained_lstm_models/lstm_model_cluster_3.h5\n",
            "Model for cluster 4 loaded from trained_lstm_models/lstm_model_cluster_4.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the new data (replace 'path_to_new_data.csv' with your file path)\n",
        "new_data = pd.read_csv('/content/stock_data.csv')\n",
        "\n",
        "# Ensure 'date' column is in datetime format and set it as the index if necessary\n",
        "new_data['date'] = pd.to_datetime(new_data['date'])\n",
        "new_data.set_index('date', inplace=True)\n"
      ],
      "metadata": {
        "id": "brXHehRes80v"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform clustering again if necessary\n",
        "stock_features = new_data.groupby('context_id').agg({\n",
        "    'volume': ['mean'],\n",
        "    'close': ['std', 'mean'],\n",
        "}).reset_index()\n",
        "\n",
        "# Flatten column names\n",
        "stock_features.columns = ['context_id', 'avg_volume', 'volatility', 'avg_price']\n",
        "\n",
        "# Normalize numerical features\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "stock_features[['avg_volume', 'volatility', 'avg_price']] = scaler.fit_transform(\n",
        "    stock_features[['avg_volume', 'volatility', 'avg_price']]\n",
        ")\n",
        "\n",
        "# Apply clustering using the same number of clusters as used during training\n",
        "from sklearn.cluster import KMeans\n",
        "num_clusters = 5  # Set the same number of clusters as used in training\n",
        "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
        "stock_features['cluster'] = kmeans.fit_predict(stock_features[['avg_volume', 'volatility', 'avg_price']])\n",
        "\n",
        "# Merge the cluster labels back into `new_data`\n",
        "new_data = new_data.reset_index().merge(stock_features[['context_id', 'cluster']], on='context_id', how='left')\n"
      ],
      "metadata": {
        "id": "XqtbEhw5tCPI"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from datetime import timedelta\n",
        "import os\n",
        "\n",
        "n_future = 10  # Number of future days you want to predict\n",
        "n_past = 252\n",
        "# Create lists to store predictions\n",
        "all_predictions = []\n",
        "\n",
        "for cluster in range(num_clusters):\n",
        "    cluster_data = new_data[new_data['cluster'] == cluster]\n",
        "    stocks_in_cluster = cluster_data['context_id'].unique()\n",
        "    cluster_data['day_of_week'] = cluster_data['date'].dt.dayofweek\n",
        "    cluster_data['day_of_year'] = cluster_data['date'].dt.dayofyear\n",
        "\n",
        "    for stock in stocks_in_cluster:\n",
        "        stock_data = cluster_data[cluster_data['context_id'] == stock]\n",
        "        last_sequence = stock_data.iloc[-n_past:].copy()\n",
        "\n",
        "        if len(last_sequence) < n_past:\n",
        "            print(f\"Not enough data for stock {stock} in cluster {cluster}. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        # Scale the last sequence\n",
        "        last_prices = last_sequence['close'].values.reshape(-1, 1)\n",
        "        scaler = StandardScaler()\n",
        "        last_prices_scaled = scaler.fit_transform(last_prices).flatten()\n",
        "\n",
        "        # Prepare input for the model\n",
        "        X = np.concatenate([last_prices_scaled, [last_sequence['day_of_week'].iloc[-1], last_sequence['day_of_year'].iloc[-1]]])\n",
        "        X = X.reshape(1, n_past + 2, 1)\n",
        "\n",
        "        # Predict future prices\n",
        "        future_predictions = []\n",
        "        future_dates = []\n",
        "        last_date = last_sequence['date'].iloc[-1]\n",
        "\n",
        "        for _ in range(n_future):\n",
        "            predicted_scaled_price = lstm_models[cluster].predict(X, verbose=0)\n",
        "            predicted_price = scaler.inverse_transform(predicted_scaled_price)\n",
        "            future_predictions.append(predicted_price.flatten()[0])\n",
        "\n",
        "            new_day_of_week = (last_sequence['day_of_week'].iloc[-1] + 1) % 7\n",
        "            new_day_of_year = (last_sequence['day_of_year'].iloc[-1] + 1) % 365\n",
        "\n",
        "            last_prices_scaled = np.append(last_prices_scaled[1:], predicted_scaled_price.flatten())\n",
        "            X = np.concatenate([last_prices_scaled, [new_day_of_week, new_day_of_year]]).reshape(1, n_past + 2, 1)\n",
        "\n",
        "            last_date += timedelta(days=1)\n",
        "            future_dates.append(last_date)\n",
        "\n",
        "        # Collect predictions for the stock\n",
        "        stock_predictions = pd.DataFrame({\n",
        "            'date': future_dates,\n",
        "            'context_id': stock,\n",
        "            'predicted_close': future_predictions\n",
        "        })\n",
        "        all_predictions.append(stock_predictions)\n",
        "\n",
        "# Combine all predictions into a single DataFrame and save\n",
        "predictions_df = pd.concat(all_predictions, ignore_index=True)\n",
        "predictions_df.to_csv('stock_predictions.csv', index=False)\n",
        "print(\"Predictions saved to 'stock_predictions.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ri590uTmd98o",
        "outputId": "25bb93b8-674b-4bc4-916f-cbf365e77519"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-2465bbf0468a>:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  cluster_data['day_of_week'] = cluster_data['date'].dt.dayofweek\n",
            "<ipython-input-11-2465bbf0468a>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  cluster_data['day_of_year'] = cluster_data['date'].dt.dayofyear\n",
            "<ipython-input-11-2465bbf0468a>:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  cluster_data['day_of_week'] = cluster_data['date'].dt.dayofweek\n",
            "<ipython-input-11-2465bbf0468a>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  cluster_data['day_of_year'] = cluster_data['date'].dt.dayofyear\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not enough data for stock GEV in cluster 1. Skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-2465bbf0468a>:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  cluster_data['day_of_week'] = cluster_data['date'].dt.dayofweek\n",
            "<ipython-input-11-2465bbf0468a>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  cluster_data['day_of_year'] = cluster_data['date'].dt.dayofyear\n",
            "<ipython-input-11-2465bbf0468a>:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  cluster_data['day_of_week'] = cluster_data['date'].dt.dayofweek\n",
            "<ipython-input-11-2465bbf0468a>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  cluster_data['day_of_year'] = cluster_data['date'].dt.dayofyear\n",
            "<ipython-input-11-2465bbf0468a>:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  cluster_data['day_of_week'] = cluster_data['date'].dt.dayofweek\n",
            "<ipython-input-11-2465bbf0468a>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  cluster_data['day_of_year'] = cluster_data['date'].dt.dayofyear\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not enough data for stock SOLV in cluster 4. Skipping.\n",
            "Not enough data for stock SW in cluster 4. Skipping.\n",
            "Predictions saved to 'stock_predictions.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load historical stock data\n",
        "historical_data = pd.read_csv('/content/stock_data.csv')\n",
        "historical_data['date'] = pd.to_datetime(historical_data['date'])\n",
        "\n",
        "# Load the predicted data (next 30 days)\n",
        "predicted_data = pd.read_csv('/content/stock_predictions.csv')\n",
        "predicted_data['date'] = pd.to_datetime(predicted_data['date'])\n",
        "\n",
        "# Select relevant columns from both datasets, ensuring the same structure\n",
        "# Assuming 'context_id' represents stock symbol and 'close' for historical data corresponds to 'predicted_close' for predicted data\n",
        "predicted_data = predicted_data.rename(columns={'predicted_close': 'close'})\n",
        "\n",
        "# Combine the datasets while keeping all the historical data and adding the new predicted rows\n",
        "combined_data = pd.concat([historical_data, predicted_data], ignore_index=True)\n",
        "\n",
        "# Sort the combined data by 'date' and 'context_id' to maintain chronological order\n",
        "combined_data = combined_data.sort_values(by=['date', 'context_id'])\n",
        "\n",
        "# Save the combined data to a new CSV file\n",
        "combined_data.to_csv('combined_stock_data.csv', index=False)\n",
        "\n",
        "print(\"Combined dataset saved as 'combined_stock_data.csv'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htPx9UPEeEoz",
        "outputId": "2619a64b-508b-44fe-fa18-a353587db6a1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined dataset saved as 'combined_stock_data.csv'.\n"
          ]
        }
      ]
    }
  ]
}